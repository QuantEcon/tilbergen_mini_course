{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tinbergen Mini Course Day 2 Homework\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Let $X$ be an $n \\times n$ matrix with all positive elements.  The spectral radius $r(X)$ of $X$ is maximum of $|\\lambda|$ over all eigenvalues $\\lambda$ of $X$, where $|\\cdot|$ is the modulus of a complex number.\n",
    "\n",
    "A version of the **local spectral radius theorem** states that if $X$ has all positive entries and $v$ is any strictly positive $n \\times 1$ vector, then\n",
    "\n",
    "$$\n",
    "    \\lim_{i \\to \\infty} \\| X^i v \\|^{1/i} \\to r(X) \n",
    "    \\qquad \\qquad \\text{(LSR)}\n",
    "$$\n",
    "\n",
    "where $\\| \\cdot \\|$ is the usual Euclidean norm.\n",
    "\n",
    "Intuitively, the norm of the iterates of a positive vector scale like $r(X)$ asymptotically.\n",
    "\n",
    "The data file `matrix_data.txt` contains the data for a single matrix $X$.  \n",
    "\n",
    "1. Read it in and compute the spectral radius using the tools for working with eigenvalues in `scipy.linalg`.\n",
    "\n",
    "2. Test the claim in (LSR) iteratively, computing $\\| X^i v \\|^{1/i}$ for successively larger values of $i$.  See if the sequence so generated converges to $r(A)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the quadratic map generates time series of the form\n",
    "\n",
    "$$ x_{t+1} = 4 \\, x_t (1 - x_t) $$\n",
    "\n",
    "for some given $x_0$, and that these trajectories are chaotic.\n",
    "\n",
    "This means that different initial conditions generate seemingly very different outcomes.\n",
    "\n",
    "Nevertheless, the regions of the state space where these trajectories spend most of their time are in fact typically invariant to the initial condition.\n",
    "\n",
    "Illustrate this by generating 100 histograms of time series generated from the quadratic map, with $x_0$ drawn independently from the uniform distribution on $(0, 1)$.  \n",
    "\n",
    "A good time series length is around 10,000.\n",
    "\n",
    "Do they all look alike?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your own version of a one dimensional [kernel density estimator](https://en.wikipedia.org/wiki/Kernel_density_estimation), which estimates a density from a sample.\n",
    "\n",
    "Write it as a class that takes the data $X$ and bandwidth $h$ when initialized and provides a method $f$ such that\n",
    "\n",
    "$$\n",
    "    f(x) = \\frac{1}{hn} \\sum_{i=1}^n \n",
    "    K \\left( \\frac{x-X_i}{h} \\right)\n",
    "$$\n",
    "\n",
    "For $K$ use the Gaussian kernel ($K$ is the standard normal density).\n",
    "\n",
    "Write the class so that the bandwidth defaults to Silverman's rule (see the \"rule of thumb\" discussion on [this page](https://en.wikipedia.org/wiki/Kernel_density_estimation)).  Test the class you have written by going through the steps\n",
    "\n",
    "1. simulate data $X_1, \\ldots, X_n$ from distribution $\\phi$\n",
    "2. plot the kernel density estimate over a suitable range\n",
    "2. plot the density of $\\phi$ on the same figure\n",
    "\n",
    "for distributions $\\phi$ of the following types\n",
    "\n",
    "\n",
    "* [beta distribution](https://en.wikipedia.org/wiki/Beta_distribution) with $\\alpha = \\beta = 2$\n",
    "* [beta distribution](https://en.wikipedia.org/wiki/Beta_distribution) with $\\alpha = 2$ and $\\beta = 5$\n",
    "* [beta distribution](https://en.wikipedia.org/wiki/Beta_distribution) with $\\alpha = \\beta = 0.5$\n",
    "\n",
    "Use $n=100$.\n",
    "\n",
    "Make a comment on your results.  (Do you think this is a good estimator of these distributions?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Consider again a simple linear regression model\n",
    "\n",
    "\n",
    "$$\n",
    "y = X \\beta + \\varepsilon \\quad \\quad \\varepsilon \\sim N(0, 1)\n",
    "$$\n",
    "\n",
    "Instead of OLS, we can use Maximum Likelihood Estimation to estimate $\\beta$\n",
    "\n",
    "We can write the distribution of $y$ as\n",
    "\n",
    "$$\n",
    "f(y) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{- \\frac{1}{2 \\sigma^2}(y - X \\beta)^2}\n",
    "$$\n",
    "\n",
    "This implies the log-likelihood is\n",
    "\n",
    "$$\n",
    "\\log \\mathcal{L} = - \\frac{T}{2} \\log 2 \\pi \\sigma^2 - \\frac{1}{2 \\sigma^2}\n",
    "\\sum_{t=1}^{T} (y_t - \\beta x_t)^2 \\quad \\quad \\text{where } \\sigma^2 = 1\n",
    "$$\n",
    "\n",
    "Given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y = np.array([3, 7, 10, 5])\n",
    "X = np.array([[5, 3], \n",
    "              [2, 3], \n",
    "              [3, 1], \n",
    "              [2, 8]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate $\\beta$ using maximum likelihood estimation\n",
    "\n",
    "Hints: \n",
    "* $y_t - X \\beta$ is the sum of squared errors\n",
    "* Write a function `logL` that returns the *negative* of the log-likelihood function\n",
    "* `x0` should be a (2 x 1) vector (this is an initial guess for $\\beta$)\n",
    "* Use scipy's `minimize` function to find $\\beta$ given $y$ and $X$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
